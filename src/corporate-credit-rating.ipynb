{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corporate Credit Rating with Synthetic Data Based on the Altman Z-score model\n",
    "\n",
    "You may use this notebook as a template for a _*text-enhanced*_ credit rating model. It shows how to take a model based on numeric features (in this case, Altman's famous 5 financial ratios) combined with texts from SEC filings so as to achieve an improvement in the prediction of credit ratings. You are not restricted to the 5 Altman ratios; you can add more variables as needed or completely change the variables. \n",
    "\n",
    "The main objective of this solution notebook is to show how SageMaker JumpStart Industry can help process NLP scoring of SEC filings text and use the [Altman's Z-score](https://www.creditguru.com/index.php/bankruptcy-and-insolvency/altman-z-score-insolvency-predictor) to compute the Altman's 5 financial ratios to enhance features, train a model using the enhanced features to achieve a best-in-class model, deploy the model to a SageMaker endpoint for production, and receive improved predictions in real time.\n",
    "\n",
    ">**<span style=\"color:RED\">Important</span>**: \n",
    ">This solution is for demonstrative purposes only. It is not financial advice and should not be relied on as financial or investment advice. The associated notebooks, including the trained model, use synthetic data, and are not intended for production.\n",
    "\n",
    "\n",
    "## What is Altman's Z-score?\n",
    "\n",
    "The [Altman's Z-score](https://www.creditguru.com/index.php/bankruptcy-and-insolvency/altman-z-score-insolvency-predictor) uses Management Discussion and Analysis (**MDNA**) text data from SEC 10-K/Q filings, [SIC code](https://www.sec.gov/corpfin/division-of-corporation-finance-standard-industrial-classification-sic-code-list) (**industry_code**), and **8 financial variables** from a company's financial statement, such as balance sheet tables and income statements. The 8 financial features are as follows: \n",
    "\n",
    "1. Current assets\n",
    "2. Current liabilities\n",
    "3. Total liabilities\n",
    "4. EBIT (earnings before interest and tax)\n",
    "5. Total assets\n",
    "6. Net sales\n",
    "7. Retained earnings\n",
    "8. Market value of equity\n",
    "\n",
    "The true label is the **Rating** column. \n",
    "\n",
    "The following snapshot shows an example of the input data:\n",
    "\n",
    "![Input data](https://sagemaker-solutions-prod-us-east-2.s3.us-east-2.amazonaws.com/sagemaker-corporate-credit-rating/0.0.1/docs/input_data.png)\n",
    "\n",
    "These 8 input features translate into the 5 financial ratios that are used for the Altman Z-score:  \n",
    "\n",
    "* A: EBIT / total assets \n",
    "* B: Net sales / total assets\n",
    "* C: Market value of equity / total liabilities\n",
    "* D: Working capital / total assets\n",
    "* E: Retained earnings / total assets\n",
    "\n",
    ">**Reference**:\n",
    ">1. Balance sheet data: https://fred.stlouisfed.org/release/tables?rid=434&eid=196197\n",
    ">2. Income statement data: https://fred.stlouisfed.org/release/tables?rid=434&eid=195208\n",
    ">3. Price to book : http://pages.stern.nyu.edu/~adamodar/New_Home_Page/datafile/pbvdata.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Read in the SageMaker JumpStart Solution configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "SOLUTION_CONFIG = json.load(open(\"stack_outputs.json\"))\n",
    "ROLE = SOLUTION_CONFIG[\"IamRole\"]\n",
    "SOLUTION_BUCKET = SOLUTION_CONFIG[\"SolutionS3Bucket\"]\n",
    "REGION = SOLUTION_CONFIG[\"AWSRegion\"]\n",
    "SOLUTION_NAME = SOLUTION_CONFIG[\"SolutionName\"]\n",
    "BUCKET = SOLUTION_CONFIG[\"S3Bucket\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Download and read in the synthetic multimodal dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "input_data_bucket = f\"s3://{SOLUTION_BUCKET}-{REGION}/{SOLUTION_NAME}/data\"\n",
    "print(\"solution data: \")\n",
    "S3Downloader.list(input_data_bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the input data from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_data = f\"{input_data_bucket}/CCR_data.csv\"\n",
    "!aws s3 cp $input_data ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have feature columns for **MD&A** section in the 10K/Q SEC filings, **industry_code**, and **8 corporate financial properties**. The label column is **Rating**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('CCR_data.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we convert the 8 corporate financial variables into the 5 financial ratios. We add the 5 ratios to the dataset, drop the 8 financial variables, and use the processed dataset for machine learning. The true label (**Rating**) is multicategorical, but it can be simplified in a binary fashion by grouping the ratings into two investment groups: a group above the investment grade (AAA, AA, A, BBB) and the other group below the investment grade.\n",
    "\n",
    "After the data preprocessing has completed, there are 5 numerical columns (**A, B, C, D, E**), one categorical column (**industry_code**) and a long-text column (**MDNA**). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"A\"] = df[\"EBIT\"]/df[\"TotalAssets\"]\n",
    "df[\"B\"] = df[\"NetSales\"]/df[\"TotalAssets\"]\n",
    "df[\"C\"] = df[\"MktValueEquity\"]/df[\"TotalLiabs\"]\n",
    "df[\"D\"] = (df[\"CurrentAssets\"]-df[\"CurrentLiabs\"])/df[\"TotalAssets\"]\n",
    "df[\"E\"] = df[\"RetainedEarnings\"]/df[\"TotalAssets\"]\n",
    "df = df.drop([\"TotalAssets\",\"CurrentLiabs\",\"TotalLiabs\", \"RetainedEarnings\", \"CurrentAssets\", \n",
    "              \"NetSales\", \"EBIT\", \"MktValueEquity\"], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"CCR_data_input.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Sample the input for demo purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the distribution of each rating class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Rating').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the ratio for each rating class, used for the stratified sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_ratio = {\"AAA\": len(df[df[\"Rating\"] == \"AAA\"])/len(df), \"AA\": len(df[df[\"Rating\"] == \"AA\"])/len(df), \"A\": len(df[df[\"Rating\"] == \"A\"])/len(df), \n",
    "                \"BBB\": len(df[df[\"Rating\"] == \"BBB\"])/len(df), \"BB\": len(df[df[\"Rating\"] == \"BB\"])/len(df), \"B\": len(df[df[\"Rating\"] == \"B\"])/len(df), \n",
    "                \"CCC\": len(df[df[\"Rating\"] == \"CCC\"])/len(df)}\n",
    "rating_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We randomly take 500 samples out of the synthetic data for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 500\n",
    "df_sample = pd.concat([df[df['Rating'] == k].sample(int(v * sample), replace=False, random_state=42) for k, v in rating_ratio.items()])\n",
    "df_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.to_csv(\"CCR_data_input_sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Add NLP scores to the multimodal dataset\n",
    "\n",
    "We add 11 NLP scores to the multimodal dataset using the <span style=\"color:lightgreen\">SageMaker JumpStart Industry Python SDK</span>; the client library helps trigger a SageMaker processing job for NLP scoring.\n",
    "\n",
    "The processing job will take around an hour with the sample dataset (`CCR_data_input_sample.csv`) and around 5 hours with the full dataset (`CCR_data_input.csv`) on an `ml.c5.18xlarge` processing instance. NLP scoring scales with the size of documents, and SEC filings have tens of thousands of words. After the NLP-scoring processing job has complete, you'll see that new 11 columns for the NLP scores are added to the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download dependencies and install SageMaker JumpStart Industry Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dependency_bucket = f\"s3://{SOLUTION_BUCKET}-{REGION}/{SOLUTION_NAME}/python-dependencies\"\n",
    "\n",
    "!mkdir -p python-dependencies\n",
    "!aws s3 sync $dependency_bucket python-dependencies/\n",
    "\n",
    "!pip install smjsindustry --no-index --find-links file://$PWD/python-dependencies/wheelhouse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use `ml.c5.18xlarge` for the NLPScorer processing job to reduce the running time. If `ml.c5.18xlarge` is not available in your region or account, choose one of the other processing instances. If you encounter an error message that you've exceeded your quota, use AWS Support to request a service limit increase for [SageMaker resources](https://console.aws.amazon.com/support/home#/) you want to scale up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from smjsindustry import NLPScoreType, NLPSCORE_NO_WORD_LIST\n",
    "from smjsindustry import NLPScorer, NLPScorerConfig\n",
    "\n",
    "score_type_list = list(\n",
    "    NLPScoreType(score_type, [])\n",
    "    for score_type in NLPScoreType.DEFAULT_SCORE_TYPES\n",
    "    if score_type not in NLPSCORE_NO_WORD_LIST\n",
    ")\n",
    "score_type_list.extend([NLPScoreType(score_type, None) for score_type in NLPSCORE_NO_WORD_LIST])\n",
    "nlp_scorer_config = NLPScorerConfig(score_type_list)\n",
    "\n",
    "nlp_score_processor = NLPScorer(      \n",
    "        ROLE,\n",
    "        1,                                    \n",
    "        'ml.c5.18xlarge',                       \n",
    "        volume_size_in_gb=30,                  \n",
    "        volume_kms_key=None,                    \n",
    "        output_kms_key=None,                    \n",
    "        max_runtime_in_seconds=None,            \n",
    "        sagemaker_session=sagemaker.Session(),  \n",
    "        tags=None)                             \n",
    "\n",
    "nlp_score_processor.calculate(\n",
    "    nlp_scorer_config, \n",
    "    \"MDNA\", \n",
    "    \"CCR_data_input_sample.csv\",               # replace this with CCR_data_input.csv if you want to use the full dataset\n",
    "    's3://{}/{}'.format(BUCKET, \"nlp_score\"), \n",
    "    'ccr_nlp_score_sample.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the NLP scoring result from S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "client = boto3.client('s3')\n",
    "client.download_file(BUCKET, '{}/{}'.format(\"nlp_score\", 'ccr_nlp_score_sample.csv'), 'ccr_nlp_score_sample.csv')\n",
    "df_tabtext_score = pd.read_csv('ccr_nlp_score_sample.csv')\n",
    "df_tabtext_score.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Prepare a Docker environment for model training and inference \n",
    "\n",
    "We use [GluonNLP](https://nlp.gluon.ai/) for machine learning. \n",
    "\n",
    "The following script creates a `lib` folder and a `requirements.txt` file to store AutoGluon related dependencies for SageMaker training and inference tasks. These dependencies will be installed in the training and inference containers. To learn more, see [Use third-party libraries](https://sagemaker.readthedocs.io/en/stable/frameworks/mxnet/using_mxnet.html#use-third-party-libraries) in the *SageMaker Python SDK documentation*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "! bash prepare_model_code.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Train the AutoGluon model with the SageMaker MXNet Estimator\n",
    "\n",
    "AutoGluon is built on the MXNet framework. We use [SageMaker MXNet Estimator](https://sagemaker.readthedocs.io/en/stable/frameworks/mxnet/sagemaker.mxnet.html) to train the AutoGluon model in the AWS deep learning container for MXNet. For more details about AutoGluon, see [AutoGluon: AutoML for Text, Image, and Tabular Data](https://auto.gluon.ai/stable/index.html) and [AutoGluon GitHub](https://github.com/awslabs/autogluon)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the dataset into a training dataset and a test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(\n",
    "    df_tabtext_score, test_size=0.2, random_state=42, stratify=df_tabtext_score['Rating']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "session = sagemaker.Session()\n",
    "\n",
    "train_data.to_csv(\"train_data.csv\", index=False)\n",
    "test_data.to_csv(\"test_data.csv\", index=False)\n",
    "\n",
    "train_s3_path = session.upload_data('train_data.csv', bucket=BUCKET, key_prefix='data')\n",
    "test_s3_path = session.upload_data('test_data.csv', bucket=BUCKET, key_prefix='data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following training job on an `ml.c5.2xlarge` instance takes about 17 minutes with the sample dataset. If you want to train a model with your own dataset, you may need to update the training script `train.py` in the` model-training` folder. If you want to use a GPU instance to achieve a better accuracy, replace `train_instance_type` with the desired GPU instance type and uncomment `fit_args` and `hyperparameters` to pass the number of GPUs to the training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sagemaker.mxnet import MXNet\n",
    "\n",
    "# Define required label and additional parameters for Autogluon TabularPredictor\n",
    "init_args = {\n",
    "  'label': 'Rating'\n",
    "}\n",
    "\n",
    "# Define parameters for Autogluon TabularPredictor fit method\n",
    "# fit_args = {\n",
    "#   'ag_args_fit': {'num_gpus': 1}\n",
    "# }\n",
    "\n",
    "hyperparameters = {'init_args': str(init_args)}\n",
    "# hyperparameters = {'init_args': str(init_args), 'fit_args': str(fit_args)}\n",
    "\n",
    "tags = [{'Key' : 'AlgorithmName', 'Value' : 'AutoGluon-Tabular'}, \n",
    "        {'Key' : 'ProjectName', 'Value' : 'Jumpstart-Industry-Finance'},]\n",
    "\n",
    "estimator = MXNet(\n",
    "    entry_point=\"train.py\",\n",
    "    role=ROLE,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=\"ml.c5.2xlarge\", # Specify the desired instance type\n",
    "    framework_version=\"1.8.0\",\n",
    "    py_version=\"py37\",\n",
    "    source_dir=\"model-training\",\n",
    "    base_job_name='sagemaker-soln-ccr-js-training',\n",
    "    hyperparameters=hyperparameters,\n",
    "    tags=tags,\n",
    "    disable_profiler=True,\n",
    "    debugger_hook_config=False,\n",
    "    enable_network_isolation=True,  # Set enable_network_isolation=True to ensure a security running environment\n",
    ")\n",
    "\n",
    "inputs = {'training': train_s3_path, 'testing': test_s3_path}\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the training job has completed, the following files are saved in the SageMaker session's default S3 bucket:\n",
    "* `leaderboard.csv`\n",
    "* `predictions.csv`\n",
    "* `feature_importance.csv`\n",
    "* `evaluation.json`\n",
    "* `classification_report.csv`\n",
    "* `confusion_matrix.png`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3 \n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "job_name = estimator._current_job_name\n",
    "bucket = session.default_bucket()\n",
    "s3_client.download_file(bucket, f\"{job_name}/output/output.tar.gz\", \"output.tar.gz\")\n",
    "!tar -xvzf output.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('evaluation.json') as f:\n",
    "    data = json.load(f)\n",
    "print(data)\n",
    "print(\"The test accurary is {}.\".format(data['accuracy']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display confusion matrix \n",
    "\n",
    "The following confusion matrix shows the performance of the multicategorical classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "display(Image(filename='confusion_matrix.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Deploy an endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we deploy the model artifact from **Step 6** and use for inference. We use the [SageMaker MXNet model](https://sagemaker.readthedocs.io/en/stable/frameworks/mxnet/sagemaker.mxnet.html#mxnet-model) and [SageMaker model deployment](https://sagemaker.readthedocs.io/en/stable/frameworks/mxnet/using_mxnet.html#deploy-mxnet-models) APIs to deploy an endpoint. If you bring your own data for inference, you may also need to update the inference script `inference.py` in the `model-inference` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_name = estimator.latest_training_job.name\n",
    "print(\"Training job name: \", training_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.mxnet import MXNet\n",
    "attached_estimator = MXNet.attach(training_job_name)\n",
    "attached_estimator.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.mxnet import MXNetModel\n",
    "\n",
    "endpoint_name = SOLUTION_CONFIG[\"SolutionPrefix\"] + \"-endpoint\"\n",
    "\n",
    "deployed_model = MXNetModel(\n",
    "    framework_version=\"1.8.0\", \n",
    "    py_version=\"py37\", \n",
    "    model_data=attached_estimator.model_data, \n",
    "    role=ROLE,\n",
    "    entry_point=\"inference.py\", \n",
    "    source_dir=\"model-inference\",\n",
    "    name=SOLUTION_CONFIG[\"SolutionPrefix\"] + \"-model\",\n",
    "    enable_network_isolation=True)     # Set enable_network_isolation=True to ensure a security running environment\n",
    "\n",
    "ccr_endpoint = deployed_model.deploy(\n",
    "    instance_type='ml.m5.xlarge',  \n",
    "    initial_instance_count=1,\n",
    "    endpoint_name=endpoint_name,\n",
    "    wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Test the endpoint\n",
    "\n",
    "We randomly select some data from the test dataset and test the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_endpoint_data = test_data.sample(n=5).drop([\"Rating\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import Predictor\n",
    "\n",
    "endpoint_name = SOLUTION_CONFIG[\"SolutionPrefix\"] + \"-endpoint\"  \n",
    "\n",
    "\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sagemaker.Session(),\n",
    "    deserializer=sagemaker.deserializers.JSONDeserializer(),\n",
    "    serializer=sagemaker.serializers.CSVSerializer(),\n",
    ")\n",
    "\n",
    "predictor.predict(test_endpoint_data.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Clean up the resources\n",
    "\n",
    "After you are done using this notebook, delete the model and the endpoint to avoid any incurring charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccr_endpoint.delete_model()\n",
    "ccr_endpoint.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}