{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corporate Credit Rating Endpoint Demo\n",
    "\n",
    "In this endpoint demo notebook, we demonstrate how to send inference requests to an pre-deployed endpoint and get the model response.\n",
    "\n",
    "To find more details of an end-to-end solution for model training and deployement using SageMaker, check the solution notebook `corporate-credit-rating.ipynb`. It shows how to train the AutoGluon model on a financial dataset that consists of the 5 financial ratios for Altman Z-score and eleven NLP scores based on SEC filings text so as to achieve a material improvement in the prediction of credit ratings. The exposition in this notebook is deliberately brief. \n",
    "\n",
    ">**<span style=\"color:RED\">Important</span>**: \n",
    ">This solution is for demonstrative purposes only. It is not financial advice and should not be relied on as financial or investment advice. The associated notebooks, including the trained model, use synthetic data, and are not intended for production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Read in the solution config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "SOLUTION_CONFIG = json.load(open(\"stack_outputs.json\"))\n",
    "ROLE = SOLUTION_CONFIG[\"IamRole\"]\n",
    "SOLUTION_BUCKET = SOLUTION_CONFIG[\"SolutionS3Bucket\"]\n",
    "REGION = SOLUTION_CONFIG[\"AWSRegion\"]\n",
    "SOLUTION_NAME = SOLUTION_CONFIG[\"SolutionName\"]\n",
    "BUCKET = SOLUTION_CONFIG[\"S3Bucket\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Download and read in the synthetic multimodal dataset for inference\n",
    "\n",
    "The synthetic multimodal dataset is consist of texts from the MD&A section in the 10K/Q SEC filings, the industrial classification codes, and simulated tabular data with 8 financial variables that are essential to calculate the Altmanâ€™s Z-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "input_data_bucket = f\"s3://{SOLUTION_BUCKET}-{REGION}/{SOLUTION_NAME}/data\"\n",
    "print(\"original data: \")\n",
    "S3Downloader.list(input_data_bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the data for inference from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_data = f\"{input_data_bucket}/inference_data.csv\"\n",
    "!aws s3 cp $inference_data ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"inference_data.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step, we convert 8 inputs into the following 5 financial ratios.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"A\"] = df[\"EBIT\"]/df[\"TotalAssets\"]\n",
    "df[\"B\"] = df[\"NetSales\"]/df[\"TotalAssets\"]\n",
    "df[\"C\"] = df[\"MktValueEquity\"]/df[\"TotalLiabs\"]\n",
    "df[\"D\"] = (df[\"CurrentAssets\"]-df[\"CurrentLiabs\"])/df[\"TotalAssets\"]\n",
    "df[\"E\"] = df[\"RetainedEarnings\"]/df[\"TotalAssets\"]\n",
    "df = df.drop([\"TotalAssets\",\"CurrentLiabs\",\"TotalLiabs\", \"RetainedEarnings\", \"CurrentAssets\", \n",
    "              \"NetSales\", \"EBIT\", \"MktValueEquity\"], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"inference_data_input.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Add NLP scores to the multimodal dataset\n",
    "\n",
    "We add 11 NLP scores to the multimodal dataset using the <span style=\"color:lightgreen\">SageMaker JumpStart Industry Python SDK</span>. This client library helps trigger a SageMaker processing job. Running the NLP-scoring processing job will take about 10 minutes to complete. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download dependencies and install SageMaker JumpStart Industry Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dependency_bucket = f\"s3://{SOLUTION_BUCKET}-{REGION}/{SOLUTION_NAME}/python-dependencies\"\n",
    "\n",
    "!mkdir -p python-dependencies\n",
    "!aws s3 sync $dependency_bucket python-dependencies/\n",
    "\n",
    "!pip install smjsindustry --no-index --find-links file://$PWD/python-dependencies/wheelhouse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use `ml.c5.18xlarge` for the NLPScorer processing job to reduce the running time. If `ml.c5.18xlarge` is not available in your region or account, choose one of the other processing instances. If you encounter an error message that you've exceeded your quota, use AWS Support to request a service limit increase for [SageMaker resources](https://console.aws.amazon.com/support/home#/) you want to scale up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from smjsindustry import NLPScoreType, NLPSCORE_NO_WORD_LIST\n",
    "from smjsindustry import NLPScorer, NLPScorerConfig\n",
    "\n",
    "score_type_list = list(\n",
    "    NLPScoreType(score_type, [])\n",
    "    for score_type in NLPScoreType.DEFAULT_SCORE_TYPES\n",
    "    if score_type not in NLPSCORE_NO_WORD_LIST\n",
    ")\n",
    "score_type_list.extend([NLPScoreType(score_type, None) for score_type in NLPSCORE_NO_WORD_LIST])\n",
    "nlp_scorer_config = NLPScorerConfig(score_type_list)\n",
    "\n",
    "nlp_score_processor = NLPScorer(\n",
    "        ROLE,        \n",
    "        1,                                      \n",
    "        'ml.c5.18xlarge',                        \n",
    "        volume_size_in_gb=30,                  \n",
    "        volume_kms_key=None,                  \n",
    "        output_kms_key=None,                   \n",
    "        max_runtime_in_seconds=None,            \n",
    "        sagemaker_session=sagemaker.Session(),  \n",
    "        tags=None)                              \n",
    "\n",
    "nlp_score_processor.calculate(\n",
    "    nlp_scorer_config, \n",
    "    \"MDNA\", \n",
    "    \"inference_data_input.csv\", \n",
    "    \"s3://{}/{}\".format(BUCKET, \"nlp_score\"), \n",
    "    \"ccr_nlp_score_inference.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "client = boto3.client('s3')\n",
    "client.download_file(BUCKET, '{}/{}'.format(\"nlp_score\", 'ccr_nlp_score_inference.csv'), 'ccr_nlp_score_inference.csv')\n",
    "df_tabtext_score = pd.read_csv('ccr_nlp_score_inference.csv')\n",
    "df_tabtext_score.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Test the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to use the demo endpoint successfully, your dataframe columns should be identical to the `df_tabtext_score` as shown in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import Predictor\n",
    "\n",
    "endpoint_name = SOLUTION_CONFIG[\"SolutionPrefix\"] + \"-demo-endpoint\" \n",
    "\n",
    "\n",
    "predictor = Predictor(\n",
    "    endpoint_name = endpoint_name,\n",
    "    sagemaker_session = sagemaker.Session(),\n",
    "    deserializer =  sagemaker.deserializers.JSONDeserializer(),\n",
    "    serializer = sagemaker.serializers.CSVSerializer(),\n",
    ")\n",
    "\n",
    "predictor.predict(df_tabtext_score.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}